rm(list=ls())
setwd("~/Documents/Keck Center/gas flow")
setwd("~/Colin/Keck Center/Gas Flow")
rm(list=ls())
setwd("~/Colin/Keck Center/Gas Flow")
data = read.csv("gasdata.csv")
library(dplyr)
library(MuMIn)
library(ggplot2)
library(ggpubr)
# Step 1: Get all combinations of Probe and Time
combinations <- unique(data[, c("Probe", "Time")])
# Step 2: Get the intersection of x across all combinations
x_common <- combinations %>%
split(seq(nrow(.))) %>%
lapply(function(row) {
subset(data, Probe == row$Probe & Time == row$Time)$x
}) %>%
Reduce(intersect, .)
# Step 3: Subset the data to keep only those x values
filtered_data <- data %>% filter(x %in% x_common)
initial_data = subset(filtered_data, Time == "Initial")
t.test(Velocity~Probe, initial_data)
final_data = subset(filtered_data, Time == "Final")
t.test(Velocity~Probe, final_data)
validation_data = subset(filtered_data, Time == "Validation")
t.test(Velocity~Probe, validation_data)
full_model <- lm(Velocity ~ Time * Probe * x, data = data)
options(na.action = "na.fail")  # required by dredge
model_set <- dredge(full_model)
# View top models sorted by AICc
head(model_set)
# Get the best model
best_model <- get.models(model_set, 1)[[1]]
summary(best_model)
anova(best_model)
plot(best_model)
acf(res)
res = best_model$residuals
plot(res)
plot(data$x, res)
acf(res)
ggplot(data, aes(x = Probe, y = Velocity)) + geom_boxplot() + geom_point(aes(x = Probe, y = Velocity, color = x)) + theme_bw()
data$Time <- factor(data$Time, levels = c("Initial", "Final", "Validation"))
ggplot(data, aes(x = Time, y = Velocity)) +
geom_boxplot() +
theme_bw() +
stat_compare_means(comparisons = list(
c("Initial", "Final"),
c("Final", "Validation"),
c("Initial", "Validation")
),
method = "t.test")
ggplot(data, aes(x = x, y = Velocity)) + geom_point() + theme_bw()
rm(list=ls())
setwd("~/Colin/Keck Center/Gas Flow")
data = read.csv("gasdata.csv")
library(dplyr)
library(MuMIn)
library(ggplot2)
library(ggpubr)
# Step 1: Get all combinations of Probe and Time
combinations <- unique(data[, c("Probe", "Time")])
# Step 2: Get the intersection of x across all combinations
x_common <- combinations %>%
split(seq(nrow(.))) %>%
lapply(function(row) {
subset(data, Probe == row$Probe & Time == row$Time)$x
}) %>%
Reduce(intersect, .)
# Step 3: Subset the data to keep only those x values
filtered_data <- data %>% filter(x %in% x_common)
initial_data = subset(filtered_data, Time == "Initial")
t.test(Velocity~Probe, initial_data)
final_data = subset(filtered_data, Time == "Final")
t.test(Velocity~Probe, final_data)
validation_data = subset(filtered_data, Time == "Validation")
t.test(Velocity~Probe, validation_data)
ta = read.csv("gasdata.csv")
library(dplyr)
library(MuMIn)
library(ggplot2)
library(ggpubr)
# Step 1: Get all combinations of Probe and Time
combinations <- unique(data[, c("Probe", "Time")])
# Step 2: Get the intersection of x across all combinations
x_common <- combinations %>%
split(seq(nrow(.))) %>%
lapply(function(row) {
subset(data, Probe == row$Probe & Time == row$Time)$x
}) %>%
Reduce(intersect, .)
# Step 3: Subset the data to keep only those x values
filtered_data <- data %>% filter(x %in% x_common)
initial_data = subset(filtered_data, Time == "Initial")
t.test(Velocity~Probe, initial_data)
final_data = subset(filtered_data, Time == "Final")
t.test(Velocity~Probe, final_data)
validation_data = subset(filtered_data, Time == "Validation")
t.test(Velocity~Probe, validation_data)
full_model <- lm(Velocity ~ Time * Probe * x, data = data)
options(na.action = "na.fail")  # required by dredge
model_set <- dredge(full_model)
# View top models sorted by AICc
head(model_set)
# Get the best model
best_model <- get.models(model_set, 1)[[1]]
summary(best_model)
anova(best_model)
plot(best_model)
anova(best_model)
ggplot(data, aes(x = Time, y = Velocity)) +
geom_boxplot() +
theme_bw() +
stat_compare_means(comparisons = list(
c("Initial", "Final"),
c("Final", "Validation"),
c("Initial", "Validation")
),
method = "t.test")
ggplot(data, aes(x = x, y = Velocity)) + geom_point() + theme_bw()
acf(res)
res = best_model$residuals
acf(res)
plot(data$x, res)
rm(list=ls())
setwd("~/Colin/Keck Center/Gas Flow")
# Define factors
colonyID <- c("A", "B", "C", "D")
treatment <- c("Brood", "No Brood")
n0 <- c(1, 3, 5, 7, 9)
set.seed(123)
# Generate blocks for each colony-treatment combo
blocks <- do.call(rbind, lapply(colonyID, function(col) {
lapply(treatment, function(trt) {
block_df <- data.frame(
colonyID = col,
Treatment = trt,
n0 = sample(n0)  # random order of n0 within this block
)
# Add a block label (colony-treatment pair)
block_df$BlockID <- paste0("Block_", col, "_", trt)
block_df
})
}))
# Flatten list into dataframe
blocks_df <- do.call(rbind, blocks)
# Randomize order of blocks (colony × treatment combos)
block_order <- sample(unique(blocks_df$BlockID))
blocks_df$BlockOrder <- match(blocks_df$BlockID, block_order)
# Sort by randomized block order
splitplot_randomized <- blocks_df[order(blocks_df$BlockOrder), ]
splitplot_randomized$Trial <- seq_len(nrow(splitplot_randomized))
# Drop helper columns if desired
splitplot_randomized <- splitplot_randomized[, c("Trial", "colonyID", "Treatment", "n0")]
# View
splitplot_randomized
rm(list=ls())
setwd("~/Colin/Keck Center/Gas Flow")
data = read.csv("gasdata.csv")
library(dplyr)
library(MuMIn)
library(ggplot2)
library(ggpubr)
# Step 1: Get all combinations of Probe and Time
combinations <- unique(data[, c("Probe", "Time")])
# Step 2: Get the intersection of x across all combinations
x_common <- combinations %>%
split(seq(nrow(.))) %>%
lapply(function(row) {
subset(data, Probe == row$Probe & Time == row$Time)$x
}) %>%
Reduce(intersect, .)
# Step 3: Subset the data to keep only those x values
filtered_data <- data %>% filter(x %in% x_common)
initial_data = subset(filtered_data, Time == "Initial")
t.test(Velocity~Probe, initial_data)
final_data = subset(filtered_data, Time == "Final")
t.test(Velocity~Probe, final_data)
validation_data = subset(filtered_data, Time == "Validation")
t.test(Velocity~Probe, validation_data)
full_model <- lm(Velocity ~ Time * Probe * x, data = data)
options(na.action = "na.fail")  # required by dredge
model_set <- dredge(full_model)
# View top models sorted by AICc
head(model_set)
best_model <- get.models(model_set, 1)[[1]]
summary(best_model)
anova(best_model)
ggplot(data, aes(x = x, y = Velocity)) + geom_point() + theme_bw()
res = best_model$residuals
plot(res)
plot(data$x, res)
acf(res)
ggplot(data, aes(x = Time, y = Velocity)) +
geom_boxplot() +
theme_bw() +
stat_compare_means(comparisons = list(
c("Initial", "Final"),
c("Final", "Validation"),
c("Initial", "Validation")
),
method = "t.test")
data$Time <- factor(data$Time, levels = c("Initial", "Final", "Validation"))
ggplot(data, aes(x = Time, y = Velocity)) +
geom_boxplot() +
theme_bw() +
stat_compare_means(comparisons = list(
c("Initial", "Final"),
c("Final", "Validation"),
c("Initial", "Validation")
),
method = "t.test")
rm(list=ls())
setwd("~/Colin/Keck Center/Gas Flow")
# Define factors
colonyID <- c("A", "B", "C", "D")
treatment <- c("Brood", "No Brood")
n0 <- c(1, 3, 5, 7, 9)
set.seed(123)
# Generate blocks for each colony-treatment combo
blocks <- do.call(rbind, lapply(colonyID, function(col) {
lapply(treatment, function(trt) {
block_df <- data.frame(
colonyID = col,
Treatment = trt,
n0 = sample(n0)  # random order of n0 within this block
)
# Add a block label (colony-treatment pair)
block_df$BlockID <- paste0("Block_", col, "_", trt)
block_df
})
}))
# Flatten list into dataframe
blocks_df <- do.call(rbind, blocks)
# Randomize order of blocks (colony × treatment combos)
block_order <- sample(unique(blocks_df$BlockID))
blocks_df$BlockOrder <- match(blocks_df$BlockID, block_order)
# Sort by randomized block order
splitplot_randomized <- blocks_df[order(blocks_df$BlockOrder), ]
splitplot_randomized$Trial <- seq_len(nrow(splitplot_randomized))
# Drop helper columns if desired
splitplot_randomized <- splitplot_randomized[, c("Trial", "colonyID", "Treatment", "n0")]
# View
splitplot_randomized
View(splitplot_randomized)
write.csv(splitplot_randomized, "DesignMatrix.csv")
#' @return A list of numeric vectors. Each vector contains \code{b + 1} bin edges for the corresponding column in \code{data}.
#'         The first edge is \code{-Inf} and the last is \code{Inf}, ensuring all values fall into some bin. Values must be real numbers.
#'
#' @examples
#' df <- data.frame(a = rnorm(100), b = runif(100))
#' binLimits(df, b = 4)
#'
#' @export
binLimits <- function(data, b) {
# Define the percentile breakpoints
percentileVec <- seq(0, 1, length.out = b + 1)
# Compute bin edges for each column
bin_limits_list <- lapply(data, function(col) {
bins <- quantile(col, percentileVec, na.rm = TRUE)
bins[1] <- -Inf
bins[length(bins)] <- Inf
return(bins)
})
return(bin_limits_list)
#' Compute Percentile-Based Bin Limits for Each Variable
#'
#' This function divides each variable (column) of a numeric data frame into \code{b} bins based on percentile cutoffs.
#' It returns a list of bin edge vectors, one for each column, where the first and last edges are set to \code{-Inf} and \code{Inf}, respectively, to cover all values.
#'
#' @param data A data frame or list where each element (column) is a numeric vector to be binned.
#' @param b An integer specifying the number of bins (must be >= 1).
#'
#' @return A list of numeric vectors. Each vector contains \code{b + 1} bin edges for the corresponding column in \code{data}.
#'         The first edge is \code{-Inf} and the last is \code{Inf}, ensuring all values fall into some bin. Values must be real numbers.
#'
#' @examples
#' df <- data.frame(a = rnorm(100), b = runif(100))
#' binLimits(df, b = 4)
#'
#' @export
binLimits <- function(data, b) {
# Define the percentile breakpoints
percentileVec <- seq(0, 1, length.out = b + 1)
# Compute bin edges for each column
bin_limits_list <- lapply(data, function(col) {
bins <- quantile(col, percentileVec, na.rm = TRUE)
bins[1] <- -Inf
bins[length(bins)] <- Inf
return(bins)
})
return(bin_limits_list)
}
setwd("~/Colin/Keck Center/Equivelancy/Multivariate case/MultivariateEquivalency/R")
devtools::document()
git init
